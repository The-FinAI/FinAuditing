{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8e1bd3-faf7-46e7-808e-ebf5ea657603",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import List, Tuple, Dict, Any, Optional\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da68780b-e635-434c-ab4b-43ed8be7e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"Reversal\", \"Inappropriateness\", \"CombinationErr\"]\n",
    "INVALID_LABEL = \"invalid\"\n",
    "\n",
    "# Allows for some common variations/case differences/spaces/punctuation\n",
    "_CANONICAL = {\n",
    "    \"reversal\": \"Reversal\",\n",
    "    \"inappropriateness\": \"Inappropriateness\",\n",
    "    \"combinationerr\": \"CombinationErr\",\n",
    "    \"combination_err\": \"CombinationErr\",\n",
    "    \"combination error\": \"CombinationErr\",\n",
    "    \"combination\": \"CombinationErr\",\n",
    "}\n",
    "\n",
    "_CODEBLOCK_RE = re.compile(r\"^```[a-zA-Z0-9]*\\n([\\s\\S]*?)\\n```$\", re.M)\n",
    "_QUOTED_RE = re.compile(r'^[\\'\"](.+)[\\'\"]$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ed0a0-66aa-4ce7-b40d-0303fdceb956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_findre_pred(pred_text: Any) -> str:\n",
    "    \"\"\"\n",
    "    Convert raw model output to one of LABELS, else INVALID_LABEL.\n",
    "\n",
    "    pred_text may include:\n",
    "      - exact label\n",
    "      - label inside quotes\n",
    "      - codeblock\n",
    "      - extra explanation text\n",
    "      - JSON like {\"label\": \"...\"} or [\"Reversal\"] etc.\n",
    "    \"\"\"\n",
    "    if pred_text is None:\n",
    "        return INVALID_LABEL\n",
    "\n",
    "    # already exact?\n",
    "    if isinstance(pred_text, str):\n",
    "        s = pred_text.strip()\n",
    "    else:\n",
    "        s = str(pred_text).strip()\n",
    "\n",
    "    if not s:\n",
    "        return INVALID_LABEL\n",
    "\n",
    "    # strip code block wrapper if present\n",
    "    m = _CODEBLOCK_RE.search(s)\n",
    "    if m:\n",
    "        s = m.group(1).strip()\n",
    "\n",
    "    # if JSON object/array, try parse\n",
    "    if (s.startswith(\"{\") and s.endswith(\"}\")) or (s.startswith(\"[\") and s.endswith(\"]\")):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            # {\"label\": \"...\"}\n",
    "            if isinstance(obj, dict):\n",
    "                for key in [\"label\", \"prediction\", \"answer\", \"output\"]:\n",
    "                    if key in obj and isinstance(obj[key], str):\n",
    "                        s = obj[key].strip()\n",
    "                        break\n",
    "            # [\"Reversal\"]\n",
    "            elif isinstance(obj, list) and len(obj) > 0:\n",
    "                s0 = obj[0]\n",
    "                s = s0.strip() if isinstance(s0, str) else str(s0).strip()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # strip outer quotes\n",
    "    m = _QUOTED_RE.match(s)\n",
    "    if m:\n",
    "        s = m.group(1).strip()\n",
    "\n",
    "    # If it contains the label somewhere in text, pick the first match\n",
    "    # (handles: \"The answer is Reversal.\" )\n",
    "    low = s.lower()\n",
    "    for key, canon in _CANONICAL.items():\n",
    "        if key in low:\n",
    "            return canon\n",
    "\n",
    "    # direct match after cleanup\n",
    "    if s in LABELS:\n",
    "        return s\n",
    "\n",
    "    # try normalize simple forms\n",
    "    s_norm = re.sub(r\"[^a-zA-Z_ ]+\", \"\", low).strip()  # keep letters/_/space\n",
    "    s_norm = re.sub(r\"\\s+\", \" \", s_norm)\n",
    "    s_norm2 = s_norm.replace(\" \", \"\")\n",
    "    if s_norm in _CANONICAL:\n",
    "        return _CANONICAL[s_norm]\n",
    "    if s_norm2 in _CANONICAL:\n",
    "        return _CANONICAL[s_norm2]\n",
    "\n",
    "    return INVALID_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93793f7-b45d-4db5-b0e8-98c311a816f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_findre_gold(gold: Any) -> str:\n",
    "    \"\"\"\n",
    "    Ground truth should already be one of LABELS, but we still normalize for safety.\n",
    "    \"\"\"\n",
    "    if gold is None:\n",
    "        return INVALID_LABEL\n",
    "    if isinstance(gold, str):\n",
    "        s = gold.strip()\n",
    "    else:\n",
    "        s = str(gold).strip()\n",
    "\n",
    "    if s in LABELS:\n",
    "        return s\n",
    "\n",
    "    # try same canonical map\n",
    "    low = s.lower()\n",
    "    low = re.sub(r\"[^a-zA-Z_ ]+\", \"\", low).strip()\n",
    "    low = re.sub(r\"\\s+\", \" \", low)\n",
    "    low2 = low.replace(\" \", \"\")\n",
    "    if low in _CANONICAL:\n",
    "        return _CANONICAL[low]\n",
    "    if low2 in _CANONICAL:\n",
    "        return _CANONICAL[low2]\n",
    "\n",
    "    return INVALID_LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb94568-92f8-447e-8ebe-16c3d9aa60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_findre_from_jsonl(\n",
    "    result_path: str,\n",
    "    pred_key: str = \"prediction\",\n",
    "    gold_key: str = \"ground_truth\",\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    true_answer: List[str] = []\n",
    "    pred_answer: List[str] = []\n",
    "\n",
    "    with open(result_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f, desc=\"Load\"):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "\n",
    "            gold_raw = obj.get(gold_key, None)\n",
    "            pred_raw = obj.get(pred_key, None)\n",
    "\n",
    "            y_true = normalize_findre_gold(gold_raw)\n",
    "            y_pred = normalize_findre_pred(pred_raw)\n",
    "\n",
    "            true_answer.append(y_true)\n",
    "            pred_answer.append(y_pred)\n",
    "\n",
    "    return true_answer, pred_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc81171-c86c-4165-8aa4-f46016ea6d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_findre(\n",
    "    result_path: str,\n",
    "    labels: List[str] = LABELS,\n",
    "    include_invalid_in_report: bool = True,\n",
    "    digits: int = 4\n",
    ") -> Dict[str, float]:\n",
    "    y_true, y_pred = load_findre_from_jsonl(result_path)\n",
    "\n",
    "    # Optional: Include invalid entries in the report (for greater transparency).\n",
    "    report_labels = labels + ([INVALID_LABEL] if include_invalid_in_report else [])\n",
    "\n",
    "    print(classification_report(y_true, y_pred, labels=report_labels, digits=digits))\n",
    "\n",
    "    # The main metrics usually only consider three categories; invalid data will affect accuracy (because it will be counted as an error).\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    macro_p = precision_score(y_true, y_pred, labels=labels, average=\"macro\", zero_division=0)\n",
    "    macro_r = recall_score(y_true, y_pred, labels=labels, average=\"macro\", zero_division=0)\n",
    "    macro_f1 = f1_score(y_true, y_pred, labels=labels, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"macro_precision\": macro_p,\n",
    "        \"macro_recall\": macro_r,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"n\": len(y_true),\n",
    "        \"n_invalid_pred\": sum(1 for x in y_pred if x == INVALID_LABEL),\n",
    "        \"n_invalid_gold\": sum(1 for x in y_true if x == INVALID_LABEL),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1269a961-dcba-4b61-822b-05ce9457964f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics = evaluate_findre(\"predictions.jsonl\")\n",
    "# print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebd157b-3efe-4b0e-8d28-67d24dbd17b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
